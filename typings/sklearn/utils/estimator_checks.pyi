"""
This type stub file was generated by pyright.
"""

from typing import Callable, Literal
from ._param_validation import StrOptions, validate_params
from ._testing import ignore_warnings

"""Various utilities to check the compatibility of estimators with scikit-learn API."""
REGRESSION_DATASET = ...
def estimator_checks_generator(estimator, *, legacy: bool = ..., expected_failed_checks: dict[str, str] | None = ..., mark: Literal["xfail", "skip", None] = ...): # -> Generator[tuple[Any, partial[None]] | Any | tuple[Any, _Wrapped[..., None, ..., Never]], Any, None]:
    """Iteratively yield all check callables for an estimator.

    This function is used by
    :func:`~sklearn.utils.estimator_checks.parametrize_with_checks` and
    :func:`~sklearn.utils.estimator_checks.check_estimator` to yield all check callables
    for an estimator. In most cases, these functions should be used instead. When
    implementing a custom equivalent, please refer to their source code to
    understand how `estimator_checks_generator` is intended to be used.

    .. versionadded:: 1.6

    Parameters
    ----------
    estimator : estimator object
        Estimator instance for which to generate checks.
    legacy : bool, default=True
        Whether to include legacy checks. Over time we remove checks from this category
        and move them into their specific category.
    expected_failed_checks : dict[str, str], default=None
        Dictionary of the form {check_name: reason} for checks that are expected to
        fail.
    mark : {"xfail", "skip"} or None, default=None
        Whether to mark the checks that are expected to fail as
        xfail(`pytest.mark.xfail`) or skip. Marking a test as "skip" is done via
        wrapping the check in a function that raises a
        :class:`~sklearn.exceptions.SkipTest` exception.

    Returns
    -------
    estimator_checks_generator : generator
        Generator that yields (estimator, check) tuples.
    """
    ...

def parametrize_with_checks(estimators, *, legacy: bool = ..., expected_failed_checks: Callable | None = ...):
    """Pytest specific decorator for parametrizing estimator checks.

    Checks are categorised into the following groups:

    - API checks: a set of checks to ensure API compatibility with scikit-learn.
      Refer to https://scikit-learn.org/dev/developers/develop.html a requirement of
      scikit-learn estimators.
    - legacy: a set of checks which gradually will be grouped into other categories.

    The `id` of each check is set to be a pprint version of the estimator
    and the name of the check with its keyword arguments.
    This allows to use `pytest -k` to specify which tests to run::

        pytest test_check_estimators.py -k check_estimators_fit_returns_self

    Parameters
    ----------
    estimators : list of estimators instances
        Estimators to generated checks for.

        .. versionchanged:: 0.24
           Passing a class was deprecated in version 0.23, and support for
           classes was removed in 0.24. Pass an instance instead.

        .. versionadded:: 0.24


    legacy : bool, default=True
        Whether to include legacy checks. Over time we remove checks from this category
        and move them into their specific category.

        .. versionadded:: 1.6

    expected_failed_checks : callable, default=None
        A callable that takes an estimator as input and returns a dictionary of the
        form::

            {
                "check_name": "my reason",
            }

        Where `"check_name"` is the name of the check, and `"my reason"` is why
        the check fails. These tests will be marked as xfail if the check fails.


        .. versionadded:: 1.6

    Returns
    -------
    decorator : `pytest.mark.parametrize`

    See Also
    --------
    check_estimator : Check if estimator adheres to scikit-learn conventions.

    Examples
    --------
    >>> from sklearn.utils.estimator_checks import parametrize_with_checks
    >>> from sklearn.linear_model import LogisticRegression
    >>> from sklearn.tree import DecisionTreeRegressor

    >>> @parametrize_with_checks([LogisticRegression(),
    ...                           DecisionTreeRegressor()])
    ... def test_sklearn_compatible_estimator(estimator, check):
    ...     check(estimator)

    """
    ...

@validate_params({ "generate_only": ["boolean"],"legacy": ["boolean"],"expected_failed_checks": [dict, None],"on_skip": [StrOptions("warn"), None],"on_fail": [StrOptions("raise", "warn"), None],"callback": [callable, None] }, prefer_skip_nested_validation=False)
def check_estimator(estimator=..., generate_only=..., *, legacy: bool = ..., expected_failed_checks: dict[str, str] | None = ..., on_skip: Literal["warn"] | None = ..., on_fail: Literal["raise", "warn"] | None = ..., callback: Callable | None = ...): # -> Generator[tuple[Any | None, partial[None]] | tuple[Any, partial[None]] | Any | tuple[Any, _Wrapped[..., None, ..., Never]], Any, None] | list[Any]:
    """Check if estimator adheres to scikit-learn conventions.

    This function will run an extensive test-suite for input validation,
    shapes, etc, making sure that the estimator complies with `scikit-learn`
    conventions as detailed in :ref:`rolling_your_own_estimator`.
    Additional tests for classifiers, regressors, clustering or transformers
    will be run if the Estimator class inherits from the corresponding mixin
    from sklearn.base.

    scikit-learn also provides a pytest specific decorator,
    :func:`~sklearn.utils.estimator_checks.parametrize_with_checks`, making it
    easier to test multiple estimators.

    Checks are categorised into the following groups:

    - API checks: a set of checks to ensure API compatibility with scikit-learn.
      Refer to https://scikit-learn.org/dev/developers/develop.html a requirement of
      scikit-learn estimators.
    - legacy: a set of checks which gradually will be grouped into other categories.

    Parameters
    ----------
    estimator : estimator object
        Estimator instance to check.

    generate_only : bool, default=False
        When `False`, checks are evaluated when `check_estimator` is called.
        When `True`, `check_estimator` returns a generator that yields
        (estimator, check) tuples. The check is run by calling
        `check(estimator)`.

        .. versionadded:: 0.22

        .. deprecated:: 1.6
            `generate_only` will be removed in 1.8. Use
            :func:`~sklearn.utils.estimator_checks.estimator_checks_generator` instead.

    legacy : bool, default=True
        Whether to include legacy checks. Over time we remove checks from this category
        and move them into their specific category.

        .. versionadded:: 1.6

    expected_failed_checks : dict, default=None
        A dictionary of the form::

            {
                "check_name": "this check is expected to fail because ...",
            }

        Where `"check_name"` is the name of the check, and `"my reason"` is why
        the check fails.

        .. versionadded:: 1.6

    on_skip : "warn", None, default="warn"
        This parameter controls what happens when a check is skipped.

        - "warn": A :class:`~sklearn.exceptions.SkipTestWarning` is logged
          and running tests continue.
        - None: No warning is logged and running tests continue.

        .. versionadded:: 1.6

    on_fail : {"raise", "warn"}, None, default="raise"
        This parameter controls what happens when a check fails.

        - "raise": The exception raised by the first failing check is raised and
          running tests are aborted. This does not included tests that are expected
          to fail.
        - "warn": A :class:`~sklearn.exceptions.EstimatorCheckFailedWarning` is logged
          and running tests continue.
        - None: No exception is raised and no warning is logged.

        Note that if ``on_fail != "raise"``, no exception is raised, even if the checks
        fail. You'd need to inspect the return result of ``check_estimator`` to check
        if any checks failed.

        .. versionadded:: 1.6

    callback : callable, or None, default=None
        This callback will be called with the estimator and the check name,
        the exception (if any), the status of the check (xfail, failed, skipped,
        passed), and the reason for the expected failure if the check is
        expected to fail. The callable's signature needs to be::

            def callback(
                estimator,
                check_name: str,
                exception: Exception,
                status: Literal["xfail", "failed", "skipped", "passed"],
                expected_to_fail: bool,
                expected_to_fail_reason: str,
            )

        ``callback`` cannot be provided together with ``on_fail="raise"``.

        .. versionadded:: 1.6

    Returns
    -------
    test_results : list
        List of dictionaries with the results of the failing tests, of the form::

            {
                "estimator": estimator,
                "check_name": check_name,
                "exception": exception,
                "status": status (one of "xfail", "failed", "skipped", "passed"),
                "expected_to_fail": expected_to_fail,
                "expected_to_fail_reason": expected_to_fail_reason,
            }

    estimator_checks_generator : generator
        Generator that yields (estimator, check) tuples. Returned when
        `generate_only=True`.

        ..
            TODO(1.8): remove return value

        .. deprecated:: 1.6
            ``generate_only`` will be removed in 1.8. Use
            :func:`~sklearn.utils.estimator_checks.estimator_checks_generator` instead.

    Raises
    ------
    Exception
        If ``on_fail="raise"``, the exception raised by the first failing check is
        raised and running tests are aborted.

        Note that if ``on_fail != "raise"``, no exception is raised, even if the checks
        fail. You'd need to inspect the return result of ``check_estimator`` to check
        if any checks failed.

    See Also
    --------
    parametrize_with_checks : Pytest specific decorator for parametrizing estimator
        checks.
    estimator_checks_generator : Generator that yields (estimator, check) tuples.

    Examples
    --------
    >>> from sklearn.utils.estimator_checks import check_estimator
    >>> from sklearn.linear_model import LogisticRegression
    >>> check_estimator(LogisticRegression())
    [...]
    """
    ...

class _NotAnArray:
    """An object that is convertible to an array.

    Parameters
    ----------
    data : array-like
        The data.
    """
    def __init__(self, data) -> None:
        ...
    
    def __array__(self, dtype=..., copy=...): # -> NDArray[Any]:
        ...
    
    def __array_function__(self, func, types, args, kwargs): # -> Literal[True]:
        ...
    


@ignore_warnings(category=FutureWarning)
def check_supervised_y_no_nan(name, estimator_orig): # -> None:
    ...

def check_array_api_input(name, estimator_orig, array_namespace, device=..., dtype_name=..., check_values=...): # -> None:
    """Check that the estimator can work consistently with the Array API

    By default, this just checks that the types and shapes of the arrays are
    consistent with calling the same estimator with numpy arrays.

    When check_values is True, it also checks that calling the estimator on the
    array_api Array gives the same results as ndarrays.
    """
    ...

def check_array_api_input_and_values(name, estimator_orig, array_namespace, device=..., dtype_name=...): # -> None:
    ...

def check_estimator_sparse_tag(name, estimator_orig): # -> None:
    """Check that estimator tag related with accepting sparse data is properly set."""
    ...

def check_estimator_sparse_matrix(name, estimator_orig): # -> None:
    ...

def check_estimator_sparse_array(name, estimator_orig): # -> None:
    ...

def check_f_contiguous_array_estimator(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_sample_weights_pandas_series(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_sample_weights_not_an_array(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_sample_weights_list(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_sample_weights_shape(name, estimator_orig): # -> None:
    ...

def check_sample_weight_equivalence_on_dense_data(name, estimator_orig): # -> None:
    ...

def check_sample_weight_equivalence_on_sparse_data(name, estimator_orig): # -> None:
    ...

def check_sample_weights_not_overwritten(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=(FutureWarning, UserWarning))
def check_dtype_object(name, estimator_orig): # -> None:
    ...

def check_complex_data(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_dict_unchanged(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_dont_overwrite_parameters(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_fit2d_predict1d(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_methods_subset_invariance(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_methods_sample_order_invariance(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_fit2d_1sample(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_fit2d_1feature(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_fit1d(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_transformer_general(name, transformer, readonly_memmap=...): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_transformer_data_not_an_array(name, transformer): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_transformers_unfitted(name, transformer): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_transformers_unfitted_stateless(name, transformer): # -> None:
    """Check that using transform without prior fitting
    doesn't raise a NotFittedError for stateless transformers.
    """
    ...

@ignore_warnings
def check_pipeline_consistency(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_mixin_order(name, estimator_orig): # -> None:
    """Check that mixins are inherited in the correct order."""
    ...

@ignore_warnings
def check_fit_score_takes_y(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_estimators_dtypes(name, estimator_orig): # -> None:
    ...

def check_transformer_preserve_dtypes(name, transformer_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_empty_data_messages(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_nan_inf(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_nonsquare_error(name, estimator_orig): # -> None:
    """Test that error is thrown when non-square data provided."""
    ...

@ignore_warnings
def check_estimators_pickle(name, estimator_orig, readonly_memmap=...): # -> None:
    """Test that we can pickle all estimators."""
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_partial_fit_n_features(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifier_multioutput(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_regressor_multioutput(name, estimator): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_clustering(name, clusterer_orig, readonly_memmap=...): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_clusterer_compute_labels_predict(name, clusterer_orig): # -> None:
    """Check that predict is invariant of compute_labels."""
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_one_label(name, classifier_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_one_label_sample_weights(name, classifier_orig): # -> None:
    """Check that classifiers accepting sample_weight fit or throws a ValueError with
    an explicit message if the problem is reduced to one class.
    """
    ...

@ignore_warnings
def check_classifiers_train(name, classifier_orig, readonly_memmap=..., X_dtype=...):
    ...

def check_outlier_corruption(num_outliers, expected_outliers, decision): # -> None:
    ...

def check_outliers_train(name, estimator_orig, readonly_memmap=...): # -> None:
    ...

def check_outlier_contamination(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_multilabel_representation_invariance(name, classifier_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_multilabel_output_format_predict(name, classifier_orig): # -> None:
    """Check the output of the `predict` method for classifiers supporting
    multilabel-indicator targets."""
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_multilabel_output_format_predict_proba(name, classifier_orig): # -> None:
    """Check the output of the `predict_proba` method for classifiers supporting
    multilabel-indicator targets."""
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_multilabel_output_format_decision_function(name, classifier_orig): # -> None:
    """Check the output of the `decision_function` method for classifiers supporting
    multilabel-indicator targets."""
    ...

@ignore_warnings(category=FutureWarning)
def check_get_feature_names_out_error(name, estimator_orig): # -> None:
    """Check the error raised by get_feature_names_out when called before fit.

    Unfitted estimators with get_feature_names_out should raise a NotFittedError.
    """
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_fit_returns_self(name, estimator_orig): # -> None:
    """Check if self is returned when calling fit."""
    ...

@ignore_warnings(category=FutureWarning)
def check_readonly_memmap_input(name, estimator_orig): # -> None:
    """Check that the estimator can handle readonly memmap backed data.

    This is particularly needed to support joblib parallelisation.
    """
    ...

@ignore_warnings
def check_estimators_unfitted(name, estimator_orig): # -> None:
    """Check that predict raises an exception in an unfitted estimator.

    Unfitted estimators should raise a NotFittedError.
    """
    ...

@ignore_warnings(category=FutureWarning)
def check_supervised_y_2d(name, estimator_orig): # -> None:
    ...

@ignore_warnings
def check_classifiers_predictions(X, y, name, classifier_orig): # -> None:
    ...

def check_classifiers_classes(name, classifier_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_regressors_int(name, regressor_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_regressors_train(name, regressor_orig, readonly_memmap=..., X_dtype=...): # -> None:
    ...

@ignore_warnings
def check_regressors_no_decision_function(name, regressor_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_class_weight_classifiers(name, classifier_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_class_weight_balanced_classifiers(name, classifier_orig, X_train, y_train, X_test, y_test, weights): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_class_weight_balanced_linear_classifier(name, estimator_orig): # -> None:
    """Test class weights with non-contiguous class labels."""
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_overwrite_params(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_no_attributes_set_in_init(name, estimator_orig): # -> None:
    """Check setting during init."""
    ...

@ignore_warnings(category=FutureWarning)
def check_sparsify_coefficients(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifier_data_not_an_array(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_regressor_data_not_an_array(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_estimators_data_not_an_array(name, estimator_orig, X, y, obj_type): # -> None:
    ...

def check_estimator_cloneable(name, estimator_orig): # -> None:
    """Checks whether the estimator can be cloned."""
    ...

def check_estimator_repr(name, estimator_orig): # -> None:
    """Check that the estimator has a functioning repr."""
    ...

def check_parameters_default_constructible(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_positive_only_tag_during_fit(name, estimator_orig): # -> None:
    """Test that the estimator correctly sets the tags.input_tags.positive_only

    If the tag is False, the estimator should accept negative input regardless of the
    tags.input_tags.pairwise flag.
    """
    ...

@ignore_warnings(category=FutureWarning)
def check_non_transformer_estimators_n_iter(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_transformer_n_iter(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_get_params_invariance(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_set_params(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_classifiers_regression_target(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_decision_proba_consistency(name, estimator_orig): # -> None:
    ...

def check_outliers_fit_predict(name, estimator_orig): # -> None:
    ...

def check_fit_non_negative(name, estimator_orig): # -> None:
    ...

def check_fit_idempotent(name, estimator_orig): # -> None:
    ...

def check_fit_check_is_fitted(name, estimator_orig): # -> None:
    ...

def check_n_features_in(name, estimator_orig): # -> None:
    ...

def check_requires_y_none(name, estimator_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_n_features_in_after_fitting(name, estimator_orig): # -> None:
    ...

def check_valid_tag_types(name, estimator): # -> None:
    """Check that estimator tags are valid."""
    ...

def check_estimator_tags_renamed(name, estimator_orig): # -> None:
    ...

def check_dataframe_column_names_consistency(name, estimator_orig): # -> None:
    ...

def check_transformer_get_feature_names_out(name, transformer_orig): # -> None:
    ...

def check_transformer_get_feature_names_out_pandas(name, transformer_orig): # -> None:
    ...

def check_param_validation(name, estimator_orig): # -> None:
    ...

def check_set_output_transform(name, transformer_orig): # -> None:
    ...

def check_set_output_transform_pandas(name, transformer_orig): # -> None:
    ...

def check_global_output_transform_pandas(name, transformer_orig): # -> None:
    ...

def check_set_output_transform_polars(name, transformer_orig): # -> None:
    ...

def check_global_set_output_transform_polars(name, transformer_orig): # -> None:
    ...

@ignore_warnings(category=FutureWarning)
def check_inplace_ensure_writeable(name, estimator_orig): # -> None:
    """Check that estimators able to do inplace operations can work on read-only
    input data even if a copy is not explicitly requested by the user.

    Make sure that a copy is made and consequently that the input array and its
    writeability are not modified by the estimator.
    """
    ...

def check_do_not_raise_errors_in_init_or_set_params(name, estimator_orig): # -> None:
    """Check that init or set_param does not raise errors."""
    ...

def check_classifier_not_supporting_multiclass(name, estimator_orig): # -> None:
    """Check that if the classifier has tags.classifier_tags.multi_class=False,
    then it should raise a ValueError when calling fit with a multiclass dataset.

    This test is not yielded if the tag is not False.
    """
    ...

